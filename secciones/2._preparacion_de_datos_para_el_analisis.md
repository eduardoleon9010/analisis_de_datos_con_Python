# **Sección 2**
## **Preparación de datos para el análisis**

En esta sección, aprenderás a realizar tareas fundamentales de manipulación de datos que son cruciales para la fase de preprocesamiento del análisis de datos. Estas tareas incluyen la gestión de valores faltantes, la estandarización y el formato de los datos, la normalización, el binning y la conversión de variables categóricas en variables numéricas, entre otras.

### Objetivos de aprendizaje

Al finalizar esta sección, serás capaz de:

1. **Gestionar valores faltantes**: Entenderás cómo identificar y tratar los valores faltantes en un conjunto de datos, y cómo decidir entre varias técnicas para manejarlos de manera adecuada.

2. **Aplicar técnicas de formato de datos**: Aprenderás cómo transformar y estandarizar datos para garantizar su consistencia y hacerlos adecuados para el análisis.

3. **Normalizar y estandarizar datos**: Podrás aplicar técnicas de normalización y estandarización para ajustar las escalas de los datos y mejorar la precisión de los modelos.

4. **Usar el binning de datos**: Aprenderás cómo agrupar los datos en contenedores (bins) para simplificar su análisis y mejorar la interpretación de los resultados.

5. **Convertir variables categóricas en variables numéricas**: Serás capaz de transformar variables categóricas en valores numéricos mediante técnicas como la codificación de etiquetas o one-hot encoding.

---
## **Preprocesamiento de Datos en Python**  

### **Introducción**  
El preprocesamiento de datos es una fase fundamental en el análisis de datos, ya que permite transformar información en bruto en un formato adecuado para su posterior exploración y modelado. Este proceso es crucial para mejorar la calidad de los datos y facilitar su análisis.  

El preprocesamiento de datos incluye varias etapas clave:  

## **1. Manejo de valores faltantes**  
Los datos pueden presentar valores ausentes, lo que puede afectar la calidad del análisis. Para ello, es necesario identificarlos y aplicar estrategias como la eliminación de registros incompletos o la imputación de valores mediante técnicas estadísticas o de aprendizaje automático.  
Existen varias formas de tratar los valores faltantes, dependiendo del contexto y la naturaleza de los datos:

### **1.1. Verificar con el origen de los datos**  
Es posible que el grupo que recopiló los datos pueda acceder a los registros originales y encontrar el valor correcto.

### **1.2. Eliminar los valores faltantes**  
Se puede optar por eliminar los datos donde faltan valores. Si solo hay unas pocas observaciones con datos faltantes, es una opción válida.  
- **Eliminar filas:** Elimina las observaciones (filas) que contienen valores faltantes.  
- **Eliminar columnas:** Si una columna tiene demasiados valores faltantes, puede ser útil eliminarla por completo.

### **1.3. Reemplazar los valores perdidos**  
En lugar de eliminar datos, otra opción es reemplazar los valores faltantes por un valor calculado, como el promedio o la moda. Esto es útil si se desea mantener todos los registros sin perder datos.  
- **Promedio para variables numéricas**: Para una columna con valores numéricos faltantes, se puede reemplazar el valor perdido con el promedio de esa columna.
- **Moda para variables categóricas**: En el caso de variables categóricas, como el tipo de combustible de un vvehiculo, se puede usar el valor más frecuente (moda).

### **1.4. Dejar los valores perdidos**  
En algunos casos, puede ser útil dejar los valores perdidos tal como están, especialmente si estos valores tienen un significado particular (por ejemplo, indicativos de datos no disponibles o ausentes por una razón específica).

### **1.5. Manejo de valores perdidos en Python con Pandas**

### **Eliminar valores perdidos**  
La biblioteca **Pandas** tiene el método `dropna()` para eliminar filas o columnas que contienen valores faltantes (`NaN`):
```python
# Eliminar filas con valores faltantes
dataframe.dropna(axis=0, inplace=True)

# Eliminar columnas con valores faltantes
dataframe.dropna(axis=1, inplace=True)
```
### **Conclusión**
Existen diversas estrategias para tratar los valores faltantes en los datos. Las opciones incluyen la eliminación de los registros incompletos o el reemplazo de los valores faltantes por estimaciones como la media o la moda. Dependiendo de la situación y la importancia de los datos, se debe elegir la estrategia más adecuada. Pandas ofrece herramientas como dropna() y fillna() para facilitar estas tareas.

## **2. Estandarización de formatos**  
Los datos provenientes de múltiples fuentes pueden tener diferencias en unidades, formatos o convenciones. Con **pandas**, es posible transformar estos datos para asegurar la coherencia en el análisis, estandarizando unidades y estructuras.  

### **2.1. Problemas comunes con el formato de los datos**
Los datos pueden tener diferentes formatos, unidades y convenciones, como cuando se hace referencia a la ciudad de Nueva York con distintas abreviaturas (N.Y., Ny, NY, New York). En la mayoría de los casos, se desea tratar estos valores de manera uniforme para facilitar el análisis posterior. Además, los datos pueden ser interpretados de diferentes maneras, y por eso es importante estandarizarlos.
### **2.2. Tipos de datos incorrectos**
A veces, al importar un conjunto de datos, los tipos de datos pueden no estar configurados correctamente. Por ejemplo, una columna que debería ser numérica puede ser interpretada como un objeto (texto). Esto puede generar problemas más adelante, ya que los modelos pueden tratar estos valores como si estuvieran faltando.

### **Conclusión**
El formateo de datos es crucial para garantizar la precisión de los análisis y modelos posteriores. Las técnicas como la conversión de unidades y la corrección de tipos de datos son fundamentales para asegurar que los datos sean consistentes y estén listos para su análisis.

## **3. Normalización de datos**  
Cuando las variables numéricas presentan escalas diferentes, la normalización permite ajustar los valores dentro de un rango común, facilitando comparaciones más significativas. Las técnicas más utilizadas incluyen el **centrado y escalado**, que ayudan a mejorar el rendimiento de los algoritmos de aprendizaje automático.  

### **3.1. ¿Por qué es importante la normalización?**
Cuando tenemos características con rangos de valores muy diferentes, como en el caso de la edad (0-100 años) y los ingresos (0-500,000), los modelos pueden ponderar más las características con valores más grandes, como los ingresos. Esto puede dar lugar a una mala interpretación de los datos, ya que las variables con menor escala, pero mayor importancia, podrían ser subestimadas.

La normalización asegura que cada característica tenga un rango de valores comparable, lo que permite que los modelos, como la regresión lineal, traten todas las variables por igual.

### **3.2. Métodos de normalización**
Existen diferentes métodos para normalizar datos. Aquí se describen tres de los más comunes:

      1. **Escalado Simple**  
Este método divide cada valor entre el valor máximo de la característica, lo que da como resultado valores entre 0 y 1.

   ```python
   # Escalado simple
   dataframe['longitud_normalizada'] = dataframe['longitud'] / dataframe['longitud'].max()
 ```
      2. **Método Mínimo-Máximo**
En este método, a cada valor se le resta el valor mínimo de la columna y luego se divide entre el rango (valor máximo - valor mínimo). Los resultados también estarán entre 0 y 1.
 ```
# Método mínimo-máximo
dataframe['longitud_normalizada'] = (dataframe['longitud'] - dataframe['longitud'].min()) / (dataframe['longitud'].max() - dataframe['longitud'].min())
 ```
     3. **Puntuación Z (Normalización Estándar)**
La puntuación Z se obtiene restando la media de la columna a cada valor y dividiendo por la desviación estándar. Esto hace que los valores resultantes estén distribuidos en torno a 0, con una desviación estándar de 1.
```
# Puntuación Z
dataframe['longitud_normalizada'] = (dataframe['longitud'] - dataframe['longitud'].mean()) / dataframe['longitud'].std()
```
### **Conclusión**
La normalización es crucial para asegurar que las características con diferentes escalas no dominen el análisis y para permitir comparaciones más justas entre ellas. Los tres métodos descritos son técnicas estándar que se pueden aplicar fácilmente con Pandas en Python.

## **4. Agrupamiento de datos**  
Este proceso permite clasificar valores numéricos en categorías más amplias, lo que resulta útil para identificar patrones y realizar comparaciones entre grupos.  

El binning, o agrupamiento, es un proceso de preprocesamiento de datos que consiste en agrupar valores numéricos en categorías o "contenedores" discretos. Este método es útil para simplificar el análisis de datos y mejorar la precisión de los modelos predictivos al reducir la variabilidad dentro de un rango de valores.

### **4.1. ¿Por qué usar Binning?**
El binning es especialmente útil cuando los valores numéricos varían ampliamente, lo que puede dificultar el análisis. Al agrupar los datos en intervalos, podemos hacer que los patrones y tendencias sean más fáciles de identificar. Un ejemplo común es agrupar edades o precios en rangos, como "precio bajo", "precio medio" y "precio alto", lo que permite una mejor comprensión de la distribución de los datos.

### 4.2. **Uso de pandas.cut:** 
Con la función cut de Pandas, podemos segmentar los datos numéricos en los contenedores definidos previamente.

### **Conclusión**
El binning es una técnica eficaz para agrupar datos continuos en categorías discretas, facilitando la interpretación y el análisis de los datos. Al reducir la cantidad de grupos, los modelos predictivos pueden trabajar de manera más eficiente, especialmente en el contexto de variables con grandes rangos de valores

## **5. Conversión de variables categóricas a numéricas**  
Muchas técnicas de modelado estadístico requieren datos numéricos, por lo que es fundamental transformar las variables categóricas mediante codificación, como **one-hot encoding** o **label encoding**.  

### **Conclusión**
La codificación en caliente es una técnica sencilla y efectiva para convertir variables categóricas en variables cuantitativas en Python, lo que permite su utilización en modelos estadísticos y de machine learning.

## **Manipulación de datos con pandas**  
En Python, las operaciones de preprocesamiento suelen aplicarse a columnas de un **DataFrame**, donde cada fila representa una observación. Las series de **pandas** permiten manipular los datos con diversas funciones, como la transformación de valores mediante operaciones aritméticas, la imputación de valores faltantes y la conversión de tipos de datos.  

## **Conclusión**  
El preprocesamiento de datos es un paso esencial en el análisis de datos, ya que garantiza que la información sea limpia, estructurada y lista para su explotación. Mediante herramientas como **pandas**, es posible aplicar técnicas eficientes de limpieza, transformación y estandarización, mejorando la precisión de los modelos y facilitando la interpretación de los resultados.  

___

## Notebooks de practica

- [Manejo de datos](https://colab.research.google.com/drive/17cgPLE9tmPlfPnvFdF8RePWDpt3cuWGw?usp=sharing)
- [Manipulacion de datos]()
