## Sección 5: Optimización de modelos y resultados

En esta sección, aprenderás sobre la importancia de la **evaluación de modelos** y cómo aplicar técnicas de **refinamiento de modelos** para mejorar la precisión y generalización de los modelos predictivos. Analizarás el proceso de **selección de modelos**, y aprenderás a identificar y abordar el **sobreajuste (overfitting)** y el **subajuste (underfitting)** en los modelos. Además, profundizarás en el uso de la **regresión de cresta** (Ridge Regression) para regularizar un modelo y reducir los errores estándar, con el objetivo de evitar el sobreajuste. También aprenderás a utilizar el **método de búsqueda en cuadrícula** para ajustar los **hiperparámetros** de los estimadores y mejorar el rendimiento del modelo.

### Objetivos de aprendizaje

Al finalizar esta sección, serás capaz de:

1. **Describir técnicas de refinamiento del modelo de datos**: Conocerás diversas técnicas para ajustar y mejorar los modelos de datos, asegurando que los modelos sean más robustos y efectivos en su predicción.

2. **Explicar el sobreajuste, el subajuste y la selección del modelo**: Aprenderás a identificar los problemas de sobreajuste y subajuste en los modelos, y cómo elegir el modelo adecuado para evitar ambos problemas.

3. **Aplicar regresión de cresta para regularizar y reducir los errores estándar**: Dominarás cómo usar la **regresión de cresta** para regularizar los modelos de regresión, reduciendo los errores estándar y previniendo el sobreajuste.

4. **Aplicar técnicas de búsqueda en cuadrícula usando Python**: Aprenderás a usar la técnica de **búsqueda en cuadrícula** para optimizar los hiperparámetros de un modelo y mejorar su rendimiento.

5. **Explicar cómo funcionan las búsquedas en cuadrícula**: Entenderás cómo funciona la búsqueda en cuadrícula y cómo puede ser utilizada para encontrar la mejor combinación de hiperparámetros en los modelos.

6. **Describir cómo funciona la regresión de cresta para evitar el sobreajuste de un modelo**: Aprenderás cómo la regresión de cresta utiliza penalizaciones en los coeficientes para evitar que el modelo se ajuste demasiado a los datos de entrenamiento, mejorando su capacidad de generalización.

---
1- **Evaluación y perfeccionamiento del Modelo en Machine Learning**

La evaluación de modelos en el campo del aprendizaje automático constituye un proceso fundamental para determinar la capacidad predictiva y de generalización de un modelo sobre datos no observados previamente. La adecuada estimación del error de generalización es esencial para evitar problemas de sobreajuste (overfitting) o subajuste (underfitting), lo que podría comprometer la aplicabilidad del modelo en entornos reales. Para ello, se implementan diversas estrategias metodológicas, siendo la división de datos en conjuntos de entrenamiento y prueba, junto con la validación cruzada, las técnicas más utilizadas.

La separación de datos en conjuntos de entrenamiento y prueba es una práctica ampliamente adoptada con el objetivo de obtener una medida realista del desempeño del modelo en datos desconocidos. El conjunto de entrenamiento permite el ajuste de los parámetros del modelo, mientras que el conjunto de prueba se emplea para evaluar su capacidad predictiva. Generalmente, se recomienda destinar entre un 70% y un 80% de los datos para el entrenamiento y el porcentaje restante para la prueba, aunque esta proporción puede variar según el tamaño del conjunto de datos y la naturaleza del problema. La principal limitación de esta estrategia radica en que la evaluación del modelo puede verse influenciada por la particularidad de los datos elegidos para la prueba, lo que podría generar una estimación sesgada del error de generalización.

Para mitigar esta problemática, se emplea la validación cruzada, una metodología que consiste en dividir el conjunto de datos en múltiples subconjuntos o folds con el fin de entrenar y evaluar el modelo de manera iterativa. En la validación cruzada k-fold, por ejemplo, el conjunto de datos se divide en k partes de tamaño similar. En cada iteración, el modelo es entrenado con k-1 subconjuntos y evaluado con el subconjunto restante. Este procedimiento se repite k veces, asegurando que cada parte del conjunto de datos sea utilizada tanto para entrenamiento como para evaluación. Finalmente, los resultados obtenidos en cada iteración se promedian, proporcionando una estimación más estable y precisa del error de generalización.

El error de generalización representa la diferencia entre el error cometido por el modelo en los datos de entrenamiento y el error en los datos de prueba. Un modelo que exhibe un error de entrenamiento bajo pero un error de prueba elevado es indicativo de sobreajuste, lo que implica que el modelo ha aprendido patrones específicos de los datos de entrenamiento sin capturar las tendencias generales del problema. Por otro lado, si el modelo presenta un error alto tanto en entrenamiento como en prueba, se considera que está subajustado, lo que sugiere que la complejidad del modelo no es suficiente para capturar la estructura subyacente de los datos. La validación cruzada permite detectar estas situaciones y ajustar hiperparámetros para optimizar el equilibrio entre sesgo y varianza.

Dentro del ecosistema de herramientas para la evaluación de modelos en aprendizaje automático, la biblioteca Scikit-learn ofrece implementaciones eficientes para la división de datos y la validación cruzada. Funciones como train_test_split permiten la separación de datos de manera aleatoria, mientras que cross_val_score y cross_val_predict facilitan la aplicación de validación cruzada, proporcionando una evaluación confiable del desempeño del modelo.

En síntesis, la evaluación de modelos en aprendizaje automático es un proceso crucial para garantizar la fiabilidad y robustez de las predicciones. La división de datos en conjuntos de entrenamiento y prueba constituye un primer paso indispensable, pero su aplicación aislada puede generar resultados sesgados. La validación cruzada emerge como una solución eficaz para mejorar la estimación del error de generalización, reduciendo la variabilidad de los resultados y favoreciendo la selección de modelos con mejor capacidad de predicción. Estas metodologías, en combinación con herramientas computacionales adecuadas, permiten el perfeccionamiento continuo de los modelos, contribuyendo a su aplicabilidad en diversos dominios del conocimiento.

2. **Sobreadaptación, inadaptación y selección de modelos**

En el análisis de datos y el aprendizaje automático, la selección de modelos es un proceso crucial para garantizar un equilibrio entre complejidad y generalización. Un modelo adecuado debe capturar las relaciones subyacentes en los datos sin ajustarse excesivamente al conjunto de entrenamiento ni ser demasiado simple como para ignorar patrones esenciales. Dentro de este contexto, se presentan dos problemas comunes: la inadaptación (underfitting) y la sobreadaptación (overfitting), los cuales pueden afectar significativamente el rendimiento de un modelo predictivo.

***Inadaptación y complejidad del modelo***

La inadaptación ocurre cuando un modelo es demasiado simple para representar la complejidad de los datos. Esto sucede, por ejemplo, cuando se intenta ajustar una función no lineal con un modelo lineal. Como resultado, el modelo presenta un error elevado tanto en el conjunto de entrenamiento como en el conjunto de prueba. En términos estadísticos, un modelo con inadaptación tiene una alta variabilidad en los residuos y no logra capturar la estructura real de los datos.

Para ilustrarlo, consideremos una regresión polinómica. Si se utiliza un polinomio de primer orden para modelar datos generados a partir de una función cuadrática o de orden superior, la predicción resultará deficiente, ya que la relación entre las variables no será adecuadamente representada. Esto implica que el modelo no solo será impreciso en el conjunto de entrenamiento, sino que también su capacidad de generalización será deficiente.

***Sobreadaptación y ruido en los datos***

En el extremo opuesto, la sobreadaptación ocurre cuando un modelo es excesivamente flexible y se ajusta no solo a la estructura de los datos sino también al ruido presente en el conjunto de entrenamiento. Esto genera una situación en la que el modelo tiene un error de entrenamiento muy bajo, pero su error en el conjunto de prueba es considerablemente mayor. Este fenómeno se manifiesta cuando se aumenta el grado de un polinomio más allá de lo necesario, logrando un ajuste perfecto a los puntos de entrenamiento pero fallando al predecir nuevos datos.

La razón principal de la sobreadaptación radica en la varianza del modelo. Un modelo con alta varianza es sensible a pequeñas fluctuaciones en los datos, lo que reduce su capacidad de generalización. Un ejemplo claro es el uso de un polinomio de orden 16 para ajustar un conjunto de datos que en realidad sigue una distribución más simple, como una función sinusoidal. En este caso, el modelo generará oscilaciones erráticas que no reflejan la verdadera relación entre las variables.

***Selección de modelos y evaluación del error***

La selección de modelos requiere encontrar un equilibrio entre la complejidad del modelo y su capacidad de generalización. Para ello, se utilizan métricas como el error cuadrático medio (MSE) y el coeficiente de determinación (R²). Un método común es la validación cruzada, que permite evaluar el rendimiento del modelo en diferentes subconjuntos de los datos.

Un gráfico del error cuadrático medio en función de la complejidad del modelo suele presentar una curva en forma de "U". En la parte izquierda de la curva, el modelo es demasiado simple y presenta inadaptación. En la parte derecha, la complejidad excesiva genera sobreadaptación. El punto óptimo se encuentra en el mínimo del error de prueba, donde el modelo logra un balance adecuado entre sesgo y varianza.

El coeficiente R² también es útil para evaluar la calidad del ajuste. Un R² cercano a 1 indica un buen ajuste del modelo, pero si se observa una disminución drástica al aumentar la complejidad, se puede inferir la presencia de sobreadaptación. La selección adecuada del orden del polinomio o del número de parámetros en un modelo más complejo se basa en minimizar el error de prueba y evitar un ajuste excesivo a los datos de entrenamiento.

**Introducción a la Regresión Ridge (Cresta)**
La regresión Ridge es una técnica utilizada para prevenir el sobreajuste en modelos de regresión. Se basa en la regularización de los coeficientes del modelo, especialmente cuando se trabaja con datos polinómicos o con múltiples variables independientes.
El sobreajuste ocurre cuando un modelo se ajusta demasiado bien a los datos de entrenamiento, capturando no solo las relaciones subyacentes sino también el ruido o valores atípicos, lo que afecta su capacidad de generalización a nuevos datos.
En el análisis de regresión, especialmente cuando se trabaja con modelos que incorporan múltiples características independientes o se utilizan expansiones polinómicas de características, es común enfrentar problemas de multicolinealidad. La multicolinealidad ocurre cuando algunas variables explicativas están altamente correlacionadas entre sí, lo que puede generar inestabilidad en la estimación de los coeficientes del modelo y aumentar la varianza de las predicciones. Esta situación puede conducir al sobreajuste, es decir, un desempeño del modelo que es óptimo en el conjunto de entrenamiento, pero deficiente en datos nuevos.

Para mitigar este problema, se emplean técnicas de regularización, que buscan reducir la complejidad del modelo y mejorar su capacidad de generalización. Una de las estrategias más utilizadas para este propósito es la Regresión de Cresta (Ridge Regression), una variante de la regresión lineal que introduce un término de penalización en la función de costo.

***Principio de la Regresión de Cresta***
La Regresión de Cresta se basa en la minimización de una función de costo modificada, que incorpora un término de regularización controlado por un hiperparámetro denominado alfa (α). Matemáticamente, el problema de optimización en la regresión lineal estándar se expresa como la minimización del error cuadrático medio (MSE)

***Aplicaciones y beneficios***
La Regresión de Cresta es especialmente útil en los siguientes escenarios:

- Datos con alta dimensionalidad: Cuando el número de predictores es grande en comparación con el número de observaciones.
- Multicolinealidad severa: Reduce la inestabilidad en la estimación de coeficientes.
- Evitar el sobreajuste: Al restringir la magnitud de los coeficientes, mejora la capacidad del modelo para generalizar.

**Regresión Ridge y búsqueda en cuadrícula**
La regresión Ridge es una variante de la regresión lineal que introduce una penalización sobre los coeficientes del modelo con el fin de reducir el sobreajuste. Para optimizar el hiperparámetro de regularización , se utiliza una técnica denominada búsqueda en cuadrícula (Grid Search), la cual explora distintas combinaciones de hiperparámetros para encontrar la mejor configuración.

**Búsqueda en cuadrícula (Grid Search)¨**
- La búsqueda en cuadrícula permite explorar de manera sistemática distintos valores de hiperparámetros, como  en la regresión Ridge. El proceso consiste en:
- Definir un conjunto de valores posibles para los hiperparámetros.
- Entrenar modelos con cada combinación de hiperparámetros.
- Evaluar el rendimiento de cada modelo mediante una métrica como el coeficiente de determinación  o el error cuadrático medio (MSE).
- Seleccionar la combinación que optimiza el rendimiento en los datos de validación.

**Conclusiones**
La selección de modelos es una tarea fundamental en el aprendizaje automático y la estadística. La inadaptación y la sobreadaptación representan extremos problemáticos en el diseño de modelos predictivos. La validación cruzada y el análisis de errores en entrenamiento y prueba son herramientas clave para determinar el modelo óptimo. Al encontrar el equilibrio entre complejidad y capacidad de generalización, se garantiza que el modelo pueda hacer predicciones precisas sobre nuevos datos, evitando tanto el subajuste como el sobreajuste.
La Regresión de Cresta es una técnica fundamental en el análisis de datos y modelado predictivo, proporcionando un enfoque robusto para manejar problemas de sobreajuste y mejorar la estabilidad de los modelos de regresión. Su implementación en herramientas como Scikit-Learn en Python permite integrarla fácilmente en flujos de trabajo de machine learning, optimizando el rendimiento en diversas aplicaciones.

- La regresión Ridge ayuda a reducir el sobreajuste al controlar la magnitud de los coeficientes del modelo.
- La búsqueda en cuadrícula permite encontrar el mejor valor de  de manera automática.

- El uso de validación cruzada garantiza una selección robusta de hiperparámetros.

**Referencias**

Géron, A. (2019). Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow. O'Reilly Media.

Bishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.

Pedregosa, F., et al. (2011). Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research, 12, 2825-2830.
___
## Notebooks de practica

- [Evaluacion y reafinamiento de datos 1]()
- [Evaluacion y reafinamiento de datos 2]()
