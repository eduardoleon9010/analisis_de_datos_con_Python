## **Seccion 1: Fuentes y obtención de datos**

En esta seccion, aprenderás los conceptos fundamentales para comprender los datos y cómo utilizar las bibliotecas de Python para importar información desde diversas fuentes. Además, adquirirás habilidades esenciales para realizar tareas iniciales que te permitirán comenzar a explorar y analizar los conjuntos de datos importados.

### Objetivos de aprendizaje

Al finalizar esta seccion, serás capaz de:

1. **Acceder a bases de datos mediante las API de Python**: Aprenderás cómo conectarte y acceder a bases de datos utilizando las interfaces de programación de aplicaciones (APIs) proporcionadas por Python para interactuar con bases de datos externas.

2. **Analizar datos utilizando un conjunto de datos en Python**: Serás capaz de cargar, manipular y realizar análisis básicos de un conjunto de datos utilizando Python, aprovechando sus poderosas bibliotecas para obtener información significativa.

4. **Identificar tres bibliotecas clave de Python y describir sus usos**: Te familiarizarás con bibliotecas fundamentales como **Pandas**, **Numpy** y **Matplotlib**, y aprenderás para qué sirve cada una de ellas en el proceso de análisis de datos.

5. **Leer datos con el paquete Pandas de Python**: Aprenderás a utilizar **Pandas** para leer y cargar datos desde distintos formatos (como CSV, Excel y bases de datos), y trabajar con estos datos de manera eficiente.

6. **Demostrar cómo importar y exportar datos en Python**: Comprenderás cómo importar datos desde diversas fuentes (archivos locales, bases de datos, APIs, etc.) y cómo exportar los resultados de tu análisis a diferentes formatos (CSV, Excel, JSON, entre otros).
___

# **Preprocesamiento de Datos en Python**  

## **Introducción**  
El preprocesamiento de datos es una fase fundamental en el análisis de datos, ya que permite transformar información en bruto en un formato adecuado para su posterior exploración y modelado. Este proceso es crucial para mejorar la calidad de los datos y facilitar su análisis.  

El preprocesamiento de datos incluye varias etapas clave:  

### **1. Manejo de valores faltantes**  
Los datos pueden presentar valores ausentes, lo que puede afectar la calidad del análisis. Para ello, es necesario identificarlos y aplicar estrategias como la eliminación de registros incompletos o la imputación de valores mediante técnicas estadísticas o de aprendizaje automático.  
Existen varias formas de tratar los valores faltantes, dependiendo del contexto y la naturaleza de los datos:

### **1.1. Verificar con el origen de los datos**  
Es posible que el grupo que recopiló los datos pueda acceder a los registros originales y encontrar el valor correcto.

### **1.2. Eliminar los valores faltantes**  
Se puede optar por eliminar los datos donde faltan valores. Si solo hay unas pocas observaciones con datos faltantes, es una opción válida.  
- **Eliminar filas:** Elimina las observaciones (filas) que contienen valores faltantes.  
- **Eliminar columnas:** Si una columna tiene demasiados valores faltantes, puede ser útil eliminarla por completo.

### **1.3. Reemplazar los valores perdidos**  
En lugar de eliminar datos, otra opción es reemplazar los valores faltantes por un valor calculado, como el promedio o la moda. Esto es útil si se desea mantener todos los registros sin perder datos.  
- **Promedio para variables numéricas**: Para una columna con valores numéricos faltantes, se puede reemplazar el valor perdido con el promedio de esa columna.
- **Moda para variables categóricas**: En el caso de variables categóricas, como el tipo de combustible de un vvehiculo, se puede usar el valor más frecuente (moda).

### **1.4. Dejar los valores perdidos**  
En algunos casos, puede ser útil dejar los valores perdidos tal como están, especialmente si estos valores tienen un significado particular (por ejemplo, indicativos de datos no disponibles o ausentes por una razón específica).

## **1.5. Manejo de valores perdidos en Python con Pandas**

### **Eliminar valores perdidos**  
La biblioteca **Pandas** tiene el método `dropna()` para eliminar filas o columnas que contienen valores faltantes (`NaN`):
```python
# Eliminar filas con valores faltantes
dataframe.dropna(axis=0, inplace=True)

# Eliminar columnas con valores faltantes
dataframe.dropna(axis=1, inplace=True)
```
### **Conclusión**
Existen diversas estrategias para tratar los valores faltantes en los datos. Las opciones incluyen la eliminación de los registros incompletos o el reemplazo de los valores faltantes por estimaciones como la media o la moda. Dependiendo de la situación y la importancia de los datos, se debe elegir la estrategia más adecuada. Pandas ofrece herramientas como dropna() y fillna() para facilitar estas tareas.

### **2. Estandarización de formatos**  
Los datos provenientes de múltiples fuentes pueden tener diferencias en unidades, formatos o convenciones. Con **pandas**, es posible transformar estos datos para asegurar la coherencia en el análisis, estandarizando unidades y estructuras.  

### **2.1. Problemas comunes con el formato de los datos**
Los datos pueden tener diferentes formatos, unidades y convenciones, como cuando se hace referencia a la ciudad de Nueva York con distintas abreviaturas (N.Y., Ny, NY, New York). En la mayoría de los casos, se desea tratar estos valores de manera uniforme para facilitar el análisis posterior. Además, los datos pueden ser interpretados de diferentes maneras, y por eso es importante estandarizarlos.
### **2.2. Tipos de datos incorrectos**
A veces, al importar un conjunto de datos, los tipos de datos pueden no estar configurados correctamente. Por ejemplo, una columna que debería ser numérica puede ser interpretada como un objeto (texto). Esto puede generar problemas más adelante, ya que los modelos pueden tratar estos valores como si estuvieran faltando.

### **Conclusión**
El formateo de datos es crucial para garantizar la precisión de los análisis y modelos posteriores. Las técnicas como la conversión de unidades y la corrección de tipos de datos son fundamentales para asegurar que los datos sean consistentes y estén listos para su análisis.

### **3. Normalización de datos**  
Cuando las variables numéricas presentan escalas diferentes, la normalización permite ajustar los valores dentro de un rango común, facilitando comparaciones más significativas. Las técnicas más utilizadas incluyen el **centrado y escalado**, que ayudan a mejorar el rendimiento de los algoritmos de aprendizaje automático.  

## **3.1. ¿Por qué es importante la normalización?**
Cuando tenemos características con rangos de valores muy diferentes, como en el caso de la edad (0-100 años) y los ingresos (0-500,000), los modelos pueden ponderar más las características con valores más grandes, como los ingresos. Esto puede dar lugar a una mala interpretación de los datos, ya que las variables con menor escala, pero mayor importancia, podrían ser subestimadas.

La normalización asegura que cada característica tenga un rango de valores comparable, lo que permite que los modelos, como la regresión lineal, traten todas las variables por igual.

## **3.2. Métodos de normalización**
Existen diferentes métodos para normalizar datos. Aquí se describen tres de los más comunes:

      1. **Escalado Simple**  
Este método divide cada valor entre el valor máximo de la característica, lo que da como resultado valores entre 0 y 1.

   ```python
   # Escalado simple
   dataframe['longitud_normalizada'] = dataframe['longitud'] / dataframe['longitud'].max()
 ```
      2. **Método Mínimo-Máximo**
En este método, a cada valor se le resta el valor mínimo de la columna y luego se divide entre el rango (valor máximo - valor mínimo). Los resultados también estarán entre 0 y 1.
 ```
# Método mínimo-máximo
dataframe['longitud_normalizada'] = (dataframe['longitud'] - dataframe['longitud'].min()) / (dataframe['longitud'].max() - dataframe['longitud'].min())
 ```
     3. **Puntuación Z (Normalización Estándar)**
La puntuación Z se obtiene restando la media de la columna a cada valor y dividiendo por la desviación estándar. Esto hace que los valores resultantes estén distribuidos en torno a 0, con una desviación estándar de 1.
```
# Puntuación Z
dataframe['longitud_normalizada'] = (dataframe['longitud'] - dataframe['longitud'].mean()) / dataframe['longitud'].std()
```
### **Conclusión**
La normalización es crucial para asegurar que las características con diferentes escalas no dominen el análisis y para permitir comparaciones más justas entre ellas. Los tres métodos descritos son técnicas estándar que se pueden aplicar fácilmente con Pandas en Python.

### **4. Agrupamiento de datos**  
Este proceso permite clasificar valores numéricos en categorías más amplias, lo que resulta útil para identificar patrones y realizar comparaciones entre grupos.  

El binning, o agrupamiento, es un proceso de preprocesamiento de datos que consiste en agrupar valores numéricos en categorías o "contenedores" discretos. Este método es útil para simplificar el análisis de datos y mejorar la precisión de los modelos predictivos al reducir la variabilidad dentro de un rango de valores.

## **4.1. ¿Por qué usar Binning?**
El binning es especialmente útil cuando los valores numéricos varían ampliamente, lo que puede dificultar el análisis. Al agrupar los datos en intervalos, podemos hacer que los patrones y tendencias sean más fáciles de identificar. Un ejemplo común es agrupar edades o precios en rangos, como "precio bajo", "precio medio" y "precio alto", lo que permite una mejor comprensión de la distribución de los datos.

### 4.2. **Uso de pandas.cut:** 
Con la función cut de Pandas, podemos segmentar los datos numéricos en los contenedores definidos previamente.

### **Conclusión**
El binning es una técnica eficaz para agrupar datos continuos en categorías discretas, facilitando la interpretación y el análisis de los datos. Al reducir la cantidad de grupos, los modelos predictivos pueden trabajar de manera más eficiente, especialmente en el contexto de variables con grandes rangos de valores

### **5. Conversión de variables categóricas a numéricas**  
Muchas técnicas de modelado estadístico requieren datos numéricos, por lo que es fundamental transformar las variables categóricas mediante codificación, como **one-hot encoding** o **label encoding**.  

### **Conclusión**
La codificación en caliente es una técnica sencilla y efectiva para convertir variables categóricas en variables cuantitativas en Python, lo que permite su utilización en modelos estadísticos y de machine learning.

## **Manipulación de datos con pandas**  
En Python, las operaciones de preprocesamiento suelen aplicarse a columnas de un **DataFrame**, donde cada fila representa una observación. Las series de **pandas** permiten manipular los datos con diversas funciones, como la transformación de valores mediante operaciones aritméticas, la imputación de valores faltantes y la conversión de tipos de datos.  

## **Conclusión**  
El preprocesamiento de datos es un paso esencial en el análisis de datos, ya que garantiza que la información sea limpia, estructurada y lista para su explotación. Mediante herramientas como **pandas**, es posible aplicar técnicas eficientes de limpieza, transformación y estandarización, mejorando la precisión de los modelos y facilitando la interpretación de los resultados.  

___
## Practica: Importación de conjuntos de datos

En esta practica, aprenderás a abordar la adquisición de datos de diversas formas y a obtener las perspectivas necesarias a partir de un conjunto de datos. Al final de esta practica, cargarás con éxito los datos en **Jupyter Notebook** y obtendrás algunas perspectivas fundamentales a través de la biblioteca **Pandas**. 

Este laboratorio utiliza **Google Colab**.

También puedes hacer clic [AQUÍ](https://github.com/eduardoleon9010/analisis_de_datos_con_Python/blob/main/documentacion/importar_datos%20(1).ipynb) para descargar el cuaderno de laboratorio (.ipynb).

- [Importacion de conjuntos de datos 1](https://colab.research.google.com/drive/1-yOhYBmnnskmM0ZEh4lt1b3cIsDorh06?authuser=7)




- [Impotacion conjunto de datos 2](https://colab.research.google.com/drive/1BBaoUlRblmKejWSTgOsh3gyzOmrdqYDh?usp=sharing)
