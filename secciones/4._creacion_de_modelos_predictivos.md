# Secci√≥n 4

## Creaci√≥n de modelos predictivos

En esta secci√≥n, aprender√°s c√≥mo desarrollar y evaluar modelos de regresi√≥n utilizando Python. Comenzar√°s por entender la diferencia entre la variable explicativa y la variable de respuesta, y c√≥mo estos conceptos se aplican en los modelos de **regresi√≥n lineal simple** y **regresi√≥n lineal m√∫ltiple**. Adem√°s, aprender√°s a evaluar un modelo visualmente, aplicar regresi√≥n polin√≥mica, y trabajar con **pipelines** para organizar el flujo de trabajo del modelo. Tambi√©n se te ense√±ar√° c√≥mo interpretar y usar las m√©tricas de evaluaci√≥n, como el **error cuadr√°tico medio (MSE)** y el **coeficiente de determinaci√≥n (R¬≤)**, para realizar evaluaciones en la muestra y determinar la calidad de los modelos. Por √∫ltimo, abordar√°s el proceso de predicci√≥n y toma de decisiones para evaluar la validez de tus modelos y su aplicabilidad.

### Objetivos de aprendizaje

Al finalizar esta secci√≥n, ser√°s capaz de:

1. **Evaluar un modelo utilizando t√©cnicas de visualizaci√≥n en Python**: Aprender√°s a representar gr√°ficamente los resultados de un modelo para facilitar la comprensi√≥n de su rendimiento.

2. **Aplicar t√©cnicas de regresi√≥n polin√≥mica utilizando Python**: Dominar√°s c√≥mo utilizar la regresi√≥n polin√≥mica para ajustar modelos a datos que siguen una relaci√≥n curvil√≠nea.

3. **Transformar los datos en un polinomio y usar regresi√≥n lineal**: Convertir√°s los datos a una forma polin√≥mica y aplicar√°s regresi√≥n lineal para ajustar el modelo y estimar los par√°metros adecuados.

4. **Aplicar la evaluaci√≥n de modelos mediante visualizaci√≥n**: Ser√°s capaz de usar visualizaciones para evaluar el rendimiento de los modelos y detectar posibles √°reas de mejora.

5. **Predecir y tomar decisiones basadas en modelos de datos**: Aprender√°s a hacer predicciones a partir de modelos de regresi√≥n y a tomar decisiones informadas basadas en los resultados obtenidos.

6. **Describir el uso de R¬≤ y MSE para la evaluaci√≥n dentro de la muestra**: Comprender√°s c√≥mo utilizar el coeficiente de determinaci√≥n **R¬≤** y el error cuadr√°tico medio **MSE** como m√©tricas clave para evaluar la precisi√≥n del modelo en los datos de entrenamiento.

7. **Definir el t√©rmino "relaci√≥n curvil√≠nea"**: Ser√°s capaz de describir lo que significa una relaci√≥n curvil√≠nea entre las variables y c√≥mo identificarla y modelarla apropiadamente.
___

## **Desarrollo de Modelos**

## **Introducci√≥n**  
Un modelo o estimador es una ecuaci√≥n matem√°tica que permite predecir un valor en funci√≥n de una o m√°s variables independientes. En el contexto del an√°lisis de precios de autom√≥viles, el modelo relaciona caracter√≠sticas del veh√≠culo (*features*) con el precio de venta (*variable dependiente*). La precisi√≥n del modelo mejora con el uso de datos relevantes y diversos, ya que una mayor cantidad de informaci√≥n reduce la incertidumbre y aumenta la exactitud de las predicciones.

### **1. Relevancia de los modelos predictivos**  
Los modelos matem√°ticos permiten establecer relaciones entre variables para realizar predicciones fundamentadas. En este caso, se busca predecir el precio de un autom√≥vil con base en caracter√≠sticas como:  

- **Consumo en carretera (millas por gal√≥n)**  
- **Color del veh√≠culo**  
- **Cilindraje del motor**  
- **Kilometraje recorrido**  

Si las variables utilizadas no son suficientes, el modelo puede producir predicciones inexactas. Por ejemplo, si el color influye significativamente en el precio pero no es considerado en el modelo, la predicci√≥n para veh√≠culos de distintos colores puede ser err√≥nea.

La regresi√≥n lineal es una t√©cnica estad√≠stica utilizada para modelar la relaci√≥n entre una variable dependiente (o de respuesta) y una o m√°s variables independientes (o predictoras). Existen dos tipos principales:  

# **Regresi√≥n lineal y regresi√≥n lineal m√∫ltiple**  

#### **2.1. Regresi√≥n Lineal Simple (SLR)**  
- Relaciona una √∫nica variable independiente con la variable dependiente.  
- Se representa con la ecuaci√≥n:  
  Y = Œ≤‚ÇÄ + Œ≤‚ÇÅX + œµ
donde (Y) es el precio del auto, X es la variable independiente (por ejemplo, millas por gal√≥n), Œ≤0 es la intersecci√≥n y Œ≤1 es el coeficiente de regresi√≥n.  

La regresi√≥n lineal simple es un m√©todo para comprender la relaci√≥n entre dos variables:  
- **Variable predictora** (independiente, *x*).  
- **Variable objetivo** (dependiente, *y*).  

Se busca establecer una relaci√≥n lineal entre estas variables.  
- **Par√°metro b‚ÇÄ**: Intercepto.  
- **Par√°metro b‚ÇÅ**: Pendiente.  

### **Ejemplo pr√°ctico**  
Si queremos predecir el precio de un autom√≥vil basado en su consumo en carretera (*millas por gal√≥n*), asumimos que hay una relaci√≥n lineal entre ambas variables. Si el consumo en carretera es 20 millas por gal√≥n, el modelo podr√≠a predecir un precio de **$22,000**.  

Para encontrar la l√≠nea de regresi√≥n:  
1. Se toman puntos de datos del conjunto de entrenamiento.  
2. Se ajusta el modelo usando estos datos para calcular los par√°metros.  
3. Los valores de entrenamiento se almacenan en estructuras de datos como DataFrames o arrays de NumPy.  
### **Ruido en los datos**  
El modelo asume que algunos factores no observados pueden afectar los resultados. Esta incertidumbre se representa como **ruido**, que es un peque√±o valor aleatorio agregado a cada punto en la l√≠nea.  

## **Proceso de Regresi√≥n**  
1. Se seleccionan los puntos de entrenamiento.  
2. Se ajusta el modelo con estos datos.  
3. Se obtienen los par√°metros *b‚ÇÄ* y *b‚ÇÅ*.  
4. Se usa el modelo para hacer predicciones.  

### **Implementaci√≥n en Python**  
Para ajustar el modelo en Python:  
1. Importar `LinearRegression` de `scikit-learn`.  
2. Crear un objeto de regresi√≥n lineal.  
3. Definir las variables predictoras (*x*) y la variable objetivo (*y*).  
4. Usar el m√©todo `.fit()` para entrenar el modelo.  
5. Obtener predicciones con `.predict()`.  

Ejemplo de ecuaci√≥n resultante:  
**Precio = 38,423.31 - 821.73 √ó (Millas por gal√≥n en carretera)** 

#### **2.2. Regresi√≥n Lineal M√∫ltiple**  
- Incluye m√∫ltiples variables independientes, mejorando la precisi√≥n de las predicciones.  
- Su ecuaci√≥n es:  
  Y = Œ≤‚ÇÄ + Œ≤‚ÇÅX‚ÇÅ + Œ≤‚ÇÇX‚ÇÇ + ... + Œ≤nXn + œµ
donde X‚ÇÅ, X‚ÇÇ, ..., Xn representan diferentes caracter√≠sticas del auto (por ejemplo, cilindrada, kilometraje, a√±o de fabricaci√≥n).

La **regresi√≥n lineal m√∫ltiple** se usa para explicar la relaci√≥n entre una variable objetivo (*y*) y dos o m√°s variables predictoras (*x*).  

Por ejemplo, si tenemos cuatro variables predictoras:  
- **b‚ÇÄ**: Intercepto.  
- **b‚ÇÅ, b‚ÇÇ, b‚ÇÉ, b‚ÇÑ**: Coeficientes de las variables *x‚ÇÅ, x‚ÇÇ, x‚ÇÉ* y *x‚ÇÑ*.  

Si hay solo dos variables (*x‚ÇÅ* y *x‚ÇÇ*), podemos visualizar los puntos en un plano 2D, donde el valor de *yÃÇ* (predicci√≥n) se representa en la altura.  

### **Ajuste del modelo**  
1. Se extraen las variables predictoras y se almacenan en una variable *Z*.  
2. Se entrena el modelo con `.fit()`.  
3. Se hacen predicciones con `.predict()`.  
4. Los coeficientes e intercepto del modelo pueden obtenerse como atributos del objeto de regresi√≥n.  

El modelo sigue la misma estructura que la regresi√≥n lineal simple, solo que ahora considera m√∫ltiples variables predictoras.  

### **3. üìä Evaluaci√≥n del modelo**  
Para determinar la precisi√≥n de un modelo se utilizan m√©tricas estad√≠sticas:  

- **Coeficiente de determinaci√≥n R^2**: Indica qu√© porcentaje de la variabilidad en los datos es explicado por el modelo. Un valor cercano a 1 sugiere una buena precisi√≥n.  
- **Error Cuadr√°tico Medio (MSE)**: Mide la diferencia promedio entre los valores reales y predichos. Un valor menor indica mejor desempe√±o.  
- **Visualizaci√≥n**: Se utilizan gr√°ficos de dispersi√≥n y curvas de ajuste para interpretar el comportamiento del modelo y detectar posibles problemas.

Exploraremos la evaluaci√≥n de modelos utilizando visualizaci√≥n. Los **gr√°ficos de regresi√≥n** nos ayudan a estimar la relaci√≥n entre dos variables, la **fuerza de la correlaci√≥n** y la **direcci√≥n de la relaci√≥n** (positiva o negativa).  

- **Eje horizontal**: Variable independiente.  
- **Eje vertical**: Variable dependiente.  
- **Cada punto**: Un valor objetivo distinto.  
- **L√≠nea ajustada**: Representa los valores predichos.  

## üìà Gr√°fico de regresi√≥n con Seaborn  
Para crear un gr√°fico de regresi√≥n, utilizamos la funci√≥n `regplot` de la librer√≠a **Seaborn**.  

### Pasos:
1. Importamos Seaborn.  
2. Utilizamos la funci√≥n `regplot()`, donde:  
   - `x` es la variable independiente.  
   - `y` es la variable dependiente.  
   - `data` es el nombre del DataFrame.  

El resultado es el gr√°fico de regresi√≥n que muestra la relaci√≥n entre las variables.  

## üìâ Gr√°fico de residuales  
Un **gr√°fico de residuales** representa el error entre el valor real y el valor predicho. Se obtiene restando el valor predicho del valor real y se representa en el eje vertical, con la variable dependiente en el eje horizontal.  

### Interpretaci√≥n:
- **Distribuci√≥n aleatoria y varianza constante** ‚Üí Indica que un modelo lineal es apropiado.  
- **Curvatura en los residuales** ‚Üí Indica que el modelo lineal no es adecuado.  
- **Aumento de la varianza con `x`** ‚Üí Indica heterocedasticidad, lo que sugiere que el modelo no es el correcto.  

Para graficar los residuales en Seaborn, usamos `residplot()`.  

## üìä Gr√°fico de distribuci√≥n  
Un **gr√°fico de distribuci√≥n** compara los valores predichos con los valores reales. Es √∫til cuando el modelo tiene m√°s de una variable independiente.  

### Pasos:
1. Se cuentan y grafican los valores predichos y reales.  
2. Pandas convierte los valores continuos en una distribuci√≥n (similar a un histograma).  
3. Se normaliza el eje vertical para que el √°rea bajo la distribuci√≥n sea igual a 1.  

### Ejemplo:
- **Valores reales** en rojo.  
- **Valores predichos** en azul.  
- Se observa qu√© tan cerca est√°n las predicciones de los valores reales.  

En **Seaborn**, para graficar la distribuci√≥n usamos:  
```python
import seaborn as sns

sns.kdeplot(actual_values, color="red", label="Actual", fill=True)
sns.kdeplot(predicted_values, color="blue", label="Predicted", fill=True)
```

#### **4. Regresi√≥n Polin√≥mica y Tuber√≠as (pipelines)**  
- Permite modelar relaciones no lineales entre las variables.  
- Se expresa como:  
  Y = Œ≤0 + Œ≤1 X + Œ≤2 X^2 + ... + Œ≤0_n X^n + œµ
 donde los t√©rminos elevados a potencias mayores a 1 capturan patrones m√°s complejos en los datos.

## üî¢ ¬øCu√°ndo usamos regresi√≥n polin√≥mica?
Cuando un modelo lineal **no se ajusta bien** a los datos, podemos utilizar una **regresi√≥n polin√≥mica**.  
Este m√©todo transforma los datos en un polinomio y luego aplica regresi√≥n lineal para ajustar los par√°metros.  
Es √∫til para describir **relaciones curvil√≠neas**, que surgen al elevar las variables predictoras a exponentes mayores.  

## üìà Tipos de modelos polin√≥micos  
- **Modelo cuadr√°tico (2¬∫ orden)**: La variable predictora se eleva al **cuadrado**.  
- **Modelo c√∫bico (3¬∫ orden)**: La variable predictora se eleva al **cubo**.  
- **Modelos de orden superior**: Se usan cuando un ajuste de 2¬∫ o 3¬∫ orden **no es suficiente**.  

üîç **Ejemplo** de regresi√≥n polin√≥mica en Python utilizando `numpy.polyfit` para un modelo de **tercer orden**:  
```python
import numpy as np

x = np.array([...])  # Valores de la variable independiente
y = np.array([...])  # Valores de la variable dependiente

coeficientes = np.polyfit(x, y, 3)
print(coeficientes)
```

# Medidas para la evaluaci√≥n en la muestra

Despu√©s de evaluar visualmente un modelo, es fundamental medir num√©ricamente su rendimiento. Para esto, utilizamos m√©tricas que determinan qu√© tan bien se ajusta el modelo a nuestros datos. Dos medidas importantes son el **Error Cuadr√°tico Medio (MSE)** y el **Coeficiente de Determinaci√≥n (R¬≤)**.

## Error Cuadr√°tico Medio (MSE)
El **MSE (Mean Squared Error)** mide la diferencia entre los valores reales y los valores predichos, elevando al cuadrado estas diferencias y calculando su promedio.

### C√°lculo del MSE
Dado un conjunto de valores reales (y) y valores predichos (yÃÇ), el MSE se calcula como:

      MSE = (1/n) * Œ£(yi-yÃÇi)^2  

Ejemplo:
- Valor real: **150**
- Valor predicho: **50**
- Diferencia: 150 - 50 = 100
- Elevado al cuadrado: 100^2 = 10000

Para calcular el MSE en Python:

```python
from sklearn.metrics import mean_squared_error
mse = mean_squared_error(y_real, y_predicho)
```
### Coeficiente de determinaci√≥n (R¬≤)
El R¬≤ mide qu√© tan cerca est√°n los datos de la l√≠nea de regresi√≥n ajustada. Se interpreta como la proporci√≥n de la variabilidad de la variable dependiente explicada por el modelo.

      C√°lculo de R¬≤
      R¬≤ = 1 ‚àí ùëÄùëÜùê∏ùëöùëúùëëùëíùëôùëú/ùëÄùëÜùê∏ùëöùëíùëëùëñùëé

Donde:
      ùëÄùëÜùê∏ùëöùëúùëëùëíùëôùëú es el MSE de la regresi√≥n.
      ùëÄùëÜùê∏ùëöùëíùëëùëñùëé es el MSE de un modelo basado solo en la media de los valores reales.

Interpretaci√≥n:
R¬≤ cercano a 1 ‚Üí El modelo es un buen ajuste.
R¬≤ cercano a 0 ‚Üí El modelo no explica la variabilidad de los datos.
R¬≤ negativo ‚Üí Puede indicar sobreajuste.

Ejemplo en Python:
```python
from sklearn.linear_model import LinearRegression

modelo = LinearRegression()
modelo.fit(X_train, y_train)
r2 = modelo.score(X_test, y_test)
```
En este caso, si obtenemos un R¬≤ de 0.49659, significa que el modelo explica aproximadamente 49.659% de la variabilidad de los datos.

### Conclusi√≥n
El MSE nos indica el error absoluto del modelo, mientras que R¬≤ mide la capacidad del modelo para explicar los datos. Un buen modelo debe minimizar el MSE y maximizar R¬≤. En casos de R¬≤ negativo, debemos revisar el modelo para evitar sobreajuste.

### **5. Predicci√≥n y toma de decisiones**  
Esta seccion aborda la importancia de la predicci√≥n y la toma de decisiones en modelos de regresi√≥n. Se enfatiza la necesidad de validar los resultados del modelo mediante visualizaci√≥n, medidas num√©ricas y comparaci√≥n con otros modelos. Se presentan ejemplos de predicci√≥n utilizando modelos de regresi√≥n y se analiza la interpretaci√≥n de los coeficientes. Tambi√©n se explican los posibles problemas al extrapolar datos y c√≥mo el an√°lisis de los residuos puede indicar la necesidad de un modelo no lineal.

- Un modelo preciso permite estimar un valor justo para un auto usado considerando factores clave.  
- Si se excluyen caracter√≠sticas relevantes, como el color en el ejemplo del auto rosa y rojo, el modelo puede hacer predicciones incorrectas.  
- Se pueden probar diferentes modelos y combinaciones de variables para mejorar la precisi√≥n.
- 
## **Introducci√≥n**
La predicci√≥n es un aspecto clave en la modelizaci√≥n estad√≠stica y el aprendizaje autom√°tico. Para validar un modelo, es fundamental asegurarse de que sus predicciones tienen sentido y no presentan valores extremos o il√≥gicos. Adem√°s, se deben utilizar herramientas visuales y m√©tricas cuantitativas para evaluar su rendimiento.

### ** Evaluaci√≥n de predicciones**
- Un modelo debe ser validado a trav√©s de visualizaciones y m√©tricas num√©ricas.
- Se usa el m√©todo `fit` para entrenar el modelo y el m√©todo `predict` para generar predicciones.
- Ejemplo: al predecir el precio de un autom√≥vil con un consumo de 30 millas por gal√≥n en carretera, el modelo estima un precio de **$13,771.30**, un valor razonable.

### ** Interpretaci√≥n de coeficientes**
- Los coeficientes (`coef_`) indican el impacto de las variables independientes sobre la variable dependiente.
- En una regresi√≥n lineal simple, un aumento de **1 unidad en el consumo en carretera** reduce el precio en aproximadamente **$821**, lo cual parece coherente.

### ** Problemas de extrapolaci√≥n**
- Si se extiende el modelo a valores fuera del rango de entrenamiento, pueden surgir predicciones poco realistas.
- Ejemplo: al predecir el precio de un autom√≥vil con consumos entre **0 y 100 mpg**, se obtienen valores negativos, lo que indica que el modelo lineal no es adecuado para esos valores.

### ** Generaci√≥n de secuencias de datos con NumPy**
- Para probar el modelo en diferentes rangos, se puede usar la funci√≥n `np.arange()`, que genera secuencias de valores de un intervalo definido.
- Se recomienda analizar visualmente los resultados con gr√°ficos de regresi√≥n.

### ** Evaluaci√≥n de modelos con m√©tricas estad√≠sticas**
- **Error cuadr√°tico medio (MSE)**: mide la desviaci√≥n promedio al cuadrado de las predicciones respecto a los valores reales.
- **Coeficiente de determinaci√≥n (R¬≤)**: mide qu√© tan bien se ajusta el modelo a los datos (valores cercanos a 1 indican un buen ajuste).

### **. Comparaci√≥n de modelos y an√°lisis de R¬≤**
- Ejemplo de valores de **R¬≤** y su interpretaci√≥n:
  - **R¬≤ = 0.9986**: el modelo se ajusta muy bien a los datos.
  - **R¬≤ = 0.9226**: el modelo a√∫n tiene una fuerte relaci√≥n lineal.
  - **R¬≤ = 0.806**: los datos son m√°s dispersos, pero la tendencia sigue siendo evidente.
  - **R¬≤ = 0.61**: la relaci√≥n lineal es m√°s d√©bil.
- Un valor aceptable de **R¬≤** depende del √°rea de estudio, pero se sugiere que sea al menos **0.10**.

### ** Comparaci√≥n entre modelos de regresi√≥n**
- **Regresi√≥n Lineal Simple (SLR) vs. Regresi√≥n Lineal M√∫ltiple (MLR)**:
  - **MLR** tiene un **MSE m√°s bajo**, pero no siempre implica un mejor modelo.
  - La inclusi√≥n de m√°s variables en MLR reduce los errores, pero puede llevar al sobreajuste.
  - **Regresi√≥n polin√≥mica** suele reducir el **MSE**, pero puede generar problemas de interpretaci√≥n.

## **Conclusiones**
- La predicci√≥n y toma de decisiones requiere la validaci√≥n rigurosa del modelo mediante m√©tricas y visualizaciones.
- Extrapolar datos fuera del rango de entrenamiento puede llevar a predicciones poco realistas.
- El an√°lisis de residuos y gr√°ficos de regresi√≥n ayudan a identificar patrones no lineales en los datos.
- **MSE y R¬≤** son herramientas clave para evaluar el rendimiento del modelo, pero deben interpretarse en contexto.
- Un menor MSE no siempre significa un mejor modelo, especialmente cuando se comparan modelos con distinta complejidad.

## **Conclusiones generales**  
El desarrollo de modelos predictivos es fundamental en el an√°lisis de datos. Utilizar regresi√≥n lineal simple, m√∫ltiple o polin√≥mica permite estimar el precio de un auto con distintos niveles de precisi√≥n. La evaluaci√≥n del modelo mediante (R¬≤) y MSE es clave para garantizar predicciones confiables. Adicional, incluir caracter√≠sticas relevantes en el modelo mejora su exactitud, evitando errores en la toma de decisiones.

A estas alturas, ya lo sabe:

- **Regresi√≥n lineal**: Se utiliza una variable independiente para hacer predicciones sobre una variable dependiente.
- **Regresi√≥n lineal m√∫ltiple**: Permite explicar la relaci√≥n entre una variable objetivo continua y dos o m√°s variables predictoras.
- **Regresi√≥n lineal simple (SLR)**: M√©todo para comprender la relaci√≥n entre dos variables: la variable independiente (`x`) y la dependiente (`y`).

### **Evaluaci√≥n y visualizaci√≥n del modelo**
- **Gr√°ficos de regresi√≥n y residuales** con `regplot` y `residplot` de Seaborn ayudan a visualizar la relaci√≥n entre las variables y evaluar la linealidad del modelo.
- **An√°lisis de residuos**: Lo ideal es que los residuos tengan media cero, est√©n distribuidos uniformemente y tengan una varianza constante. Si no se cumplen estas condiciones, es necesario ajustar el modelo.
- **Gr√°ficos de distribuci√≥n**: Son √∫tiles para comparar valores previstos y reales, especialmente en modelos con m√∫ltiples variables independientes.

### **Modelado avanzado**
- **Regresi√≥n polin√≥mica**: El orden del polinomio influye en el ajuste del modelo. Se puede utilizar `polyfit` de NumPy para desarrollar modelos que se adapten mejor a los datos.
- **Transformaci√≥n de caracter√≠sticas**: Scikit-learn ofrece herramientas como `StandardScaler` para normalizar datos y `PolynomialFeatures` para transformar variables.
- **Canalizaciones (pipelines)**: Facilitan la automatizaci√≥n de tareas como normalizaci√≥n, transformaci√≥n polin√≥mica y predicci√≥n, mejorando la eficiencia del proceso de modelado.

### **M√©tricas de evaluaci√≥n del modelo**
- **Error cuadr√°tico medio (MSE)**: Mide la media de los cuadrados de los errores entre los valores reales y los predichos.
- **Coeficiente de determinaci√≥n (R¬≤)**: Indica qu√© tan bien el modelo explica la varianza de la variable dependiente.
- Un **MSE bajo** y un **R¬≤ alto** (cercano a 1) sugieren un buen ajuste, mientras que un **R¬≤ negativo** puede indicar un sobreajuste o un modelo inadecuado.

### **Consideraciones finales**
- **Comparaci√≥n de modelos**: Se deben evaluar diferentes modelos con medidas visuales y num√©ricas antes de elegir el m√°s adecuado.
- **El MSE** es una de las m√©tricas m√°s intuitivas para evaluar modelos de regresi√≥n.
- **El gr√°fico de distribuci√≥n** es una herramienta clave en regresi√≥n lineal m√∫ltiple.
- **El valor de R¬≤ aceptable** depende del contexto y del caso de estudio.
- **An√°lisis de residuos**: Un buen modelo presenta residuos distribuidos aleatoriamente en torno a cero. Una tendencia en los residuos sugiere que el modelo puede necesitar ajustes o m√°s datos.

Para evaluar y mejorar un modelo de regresi√≥n, es fundamental utilizar herramientas de visualizaci√≥n, m√©tricas num√©ricas y ajustes adecuados en la transformaci√≥n de variables y selecci√≥n del modelo.


## **Referencias**  
- Montgomery, D. C., Peck, E. A., & Vining, G. G. (2012). *Introduction to Linear Regression Analysis*. John Wiley & Sons.  
- Hastie, T., Tibshirani, R., & Friedman, J. (2009). *The Elements of Statistical Learning: Data Mining, Inference, and Prediction*. Springer.  
- Documentaci√≥n de `sklearn.metrics` para el c√°lculo de `mean_squared_error` y `r2_score`.
- Documentaci√≥n de NumPy sobre `np.arange()` para la generaci√≥n de secuencias num√©ricas.

---

## Notebooks de practica

- [Desarrollo de modelo 1]()
- [Desarrollo de modelo 2]()
