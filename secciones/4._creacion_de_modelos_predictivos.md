# SecciÃ³n 4

## CreaciÃ³n de modelos predictivos

En esta secciÃ³n, aprenderÃ¡s cÃ³mo desarrollar y evaluar modelos de regresiÃ³n utilizando Python. ComenzarÃ¡s por entender la diferencia entre la variable explicativa y la variable de respuesta, y cÃ³mo estos conceptos se aplican en los modelos de **regresiÃ³n lineal simple** y **regresiÃ³n lineal mÃºltiple**. AdemÃ¡s, aprenderÃ¡s a evaluar un modelo visualmente, aplicar regresiÃ³n polinÃ³mica, y trabajar con **pipelines** para organizar el flujo de trabajo del modelo. TambiÃ©n se te enseÃ±arÃ¡ cÃ³mo interpretar y usar las mÃ©tricas de evaluaciÃ³n, como el **error cuadrÃ¡tico medio (MSE)** y el **coeficiente de determinaciÃ³n (RÂ²)**, para realizar evaluaciones en la muestra y determinar la calidad de los modelos. Por Ãºltimo, abordarÃ¡s el proceso de predicciÃ³n y toma de decisiones para evaluar la validez de tus modelos y su aplicabilidad.

### Objetivos de aprendizaje

Al finalizar esta secciÃ³n, serÃ¡s capaz de:

1. **Evaluar un modelo utilizando tÃ©cnicas de visualizaciÃ³n en Python**: AprenderÃ¡s a representar grÃ¡ficamente los resultados de un modelo para facilitar la comprensiÃ³n de su rendimiento.

2. **Aplicar tÃ©cnicas de regresiÃ³n polinÃ³mica utilizando Python**: DominarÃ¡s cÃ³mo utilizar la regresiÃ³n polinÃ³mica para ajustar modelos a datos que siguen una relaciÃ³n curvilÃ­nea.

3. **Transformar los datos en un polinomio y usar regresiÃ³n lineal**: ConvertirÃ¡s los datos a una forma polinÃ³mica y aplicarÃ¡s regresiÃ³n lineal para ajustar el modelo y estimar los parÃ¡metros adecuados.

4. **Aplicar la evaluaciÃ³n de modelos mediante visualizaciÃ³n**: SerÃ¡s capaz de usar visualizaciones para evaluar el rendimiento de los modelos y detectar posibles Ã¡reas de mejora.

5. **Predecir y tomar decisiones basadas en modelos de datos**: AprenderÃ¡s a hacer predicciones a partir de modelos de regresiÃ³n y a tomar decisiones informadas basadas en los resultados obtenidos.

6. **Describir el uso de RÂ² y MSE para la evaluaciÃ³n dentro de la muestra**: ComprenderÃ¡s cÃ³mo utilizar el coeficiente de determinaciÃ³n **RÂ²** y el error cuadrÃ¡tico medio **MSE** como mÃ©tricas clave para evaluar la precisiÃ³n del modelo en los datos de entrenamiento.

7. **Definir el tÃ©rmino "relaciÃ³n curvilÃ­nea"**: SerÃ¡s capaz de describir lo que significa una relaciÃ³n curvilÃ­nea entre las variables y cÃ³mo identificarla y modelarla apropiadamente.
___

## **Desarrollo de Modelos**

### **IntroducciÃ³n**  
Un modelo o estimador es una ecuaciÃ³n matemÃ¡tica que permite predecir un valor en funciÃ³n de una o mÃ¡s variables independientes. En el contexto del anÃ¡lisis de precios de automÃ³viles, el modelo relaciona caracterÃ­sticas del vehÃ­culo (*features*) con el precio de venta (*variable dependiente*). La precisiÃ³n del modelo mejora con el uso de datos relevantes y diversos, ya que una mayor cantidad de informaciÃ³n reduce la incertidumbre y aumenta la exactitud de las predicciones.

## **1. Relevancia de los modelos predictivos**  
Los modelos matemÃ¡ticos permiten establecer relaciones entre variables para realizar predicciones fundamentadas. En este caso, se busca predecir el precio de un automÃ³vil con base en caracterÃ­sticas como:  

- **Consumo en carretera (millas por galÃ³n)**  
- **Color del vehÃ­culo**  
- **Cilindraje del motor**  
- **Kilometraje recorrido**  

Si las variables utilizadas no son suficientes, el modelo puede producir predicciones inexactas. Por ejemplo, si el color influye significativamente en el precio pero no es considerado en el modelo, la predicciÃ³n para vehÃ­culos de distintos colores puede ser errÃ³nea.

La regresiÃ³n lineal es una tÃ©cnica estadÃ­stica utilizada para modelar la relaciÃ³n entre una variable dependiente (o de respuesta) y una o mÃ¡s variables independientes (o predictoras). Existen dos tipos principales:  

## **2. RegresiÃ³n lineal y regresiÃ³n lineal mÃºltiple**  

### **2.1. RegresiÃ³n Lineal Simple (SLR)**  
- Relaciona una Ãºnica variable independiente con la variable dependiente.  
- Se representa con la ecuaciÃ³n:  
  Y = Î²â‚€ + Î²â‚X + Ïµ
donde (Y) es el precio del auto, X es la variable independiente (por ejemplo, millas por galÃ³n), Î²0 es la intersecciÃ³n y Î²1 es el coeficiente de regresiÃ³n.  

La regresiÃ³n lineal simple es un mÃ©todo para comprender la relaciÃ³n entre dos variables:  
- **Variable predictora** (independiente, *x*).  
- **Variable objetivo** (dependiente, *y*).  

Se busca establecer una relaciÃ³n lineal entre estas variables.  
- **ParÃ¡metro bâ‚€**: Intercepto.  
- **ParÃ¡metro bâ‚**: Pendiente.  

**Ejemplo prÃ¡ctico**  
Si queremos predecir el precio de un automÃ³vil basado en su consumo en carretera (*millas por galÃ³n*), asumimos que hay una relaciÃ³n lineal entre ambas variables. Si el consumo en carretera es 20 millas por galÃ³n, el modelo podrÃ­a predecir un precio de **$22,000**.  

Para encontrar la lÃ­nea de regresiÃ³n:  
1. Se toman puntos de datos del conjunto de entrenamiento.  
2. Se ajusta el modelo usando estos datos para calcular los parÃ¡metros.  
3. Los valores de entrenamiento se almacenan en estructuras de datos como DataFrames o arrays de NumPy.  
### **Ruido en los datos**  
El modelo asume que algunos factores no observados pueden afectar los resultados. Esta incertidumbre se representa como **ruido**, que es un pequeÃ±o valor aleatorio agregado a cada punto en la lÃ­nea.  

**Proceso de RegresiÃ³n**  
1. Se seleccionan los puntos de entrenamiento.  
2. Se ajusta el modelo con estos datos.  
3. Se obtienen los parÃ¡metros *bâ‚€* y *bâ‚*.  
4. Se usa el modelo para hacer predicciones.  

**ImplementaciÃ³n en Python**  
Para ajustar el modelo en Python:  
1. Importar `LinearRegression` de `scikit-learn`.  
2. Crear un objeto de regresiÃ³n lineal.  
3. Definir las variables predictoras (*x*) y la variable objetivo (*y*).  
4. Usar el mÃ©todo `.fit()` para entrenar el modelo.  
5. Obtener predicciones con `.predict()`.  

Ejemplo de ecuaciÃ³n resultante:  
**Precio = 38,423.31 - 821.73 Ã— (Millas por galÃ³n en carretera)** 

## **2.2. RegresiÃ³n Lineal MÃºltiple**  
- Incluye mÃºltiples variables independientes, mejorando la precisiÃ³n de las predicciones.  
- Su ecuaciÃ³n es:  
  Y = Î²â‚€ + Î²â‚Xâ‚ + Î²â‚‚Xâ‚‚ + ... + Î²nXn + Ïµ
donde Xâ‚, Xâ‚‚, ..., Xn representan diferentes caracterÃ­sticas del auto (por ejemplo, cilindrada, kilometraje, aÃ±o de fabricaciÃ³n).

La **regresiÃ³n lineal mÃºltiple** se usa para explicar la relaciÃ³n entre una variable objetivo (*y*) y dos o mÃ¡s variables predictoras (*x*).  

Por ejemplo, si tenemos cuatro variables predictoras:  
- **bâ‚€**: Intercepto.  
- **bâ‚, bâ‚‚, bâ‚ƒ, bâ‚„**: Coeficientes de las variables *xâ‚, xâ‚‚, xâ‚ƒ* y *xâ‚„*.  

Si hay solo dos variables (*xâ‚* y *xâ‚‚*), podemos visualizar los puntos en un plano 2D, donde el valor de *yÌ‚* (predicciÃ³n) se representa en la altura.  

### **Ajuste del modelo**  
1. Se extraen las variables predictoras y se almacenan en una variable *Z*.  
2. Se entrena el modelo con `.fit()`.  
3. Se hacen predicciones con `.predict()`.  
4. Los coeficientes e intercepto del modelo pueden obtenerse como atributos del objeto de regresiÃ³n.  

El modelo sigue la misma estructura que la regresiÃ³n lineal simple, solo que ahora considera mÃºltiples variables predictoras.  

## **3. ğŸ“Š EvaluaciÃ³n del modelo**  
Para determinar la precisiÃ³n de un modelo se utilizan mÃ©tricas estadÃ­sticas:  

- **Coeficiente de determinaciÃ³n R^2**: Indica quÃ© porcentaje de la variabilidad en los datos es explicado por el modelo. Un valor cercano a 1 sugiere una buena precisiÃ³n.  
- **Error CuadrÃ¡tico Medio (MSE)**: Mide la diferencia promedio entre los valores reales y predichos. Un valor menor indica mejor desempeÃ±o.  
- **VisualizaciÃ³n**: Se utilizan grÃ¡ficos de dispersiÃ³n y curvas de ajuste para interpretar el comportamiento del modelo y detectar posibles problemas.

Exploraremos la evaluaciÃ³n de modelos utilizando visualizaciÃ³n. Los **grÃ¡ficos de regresiÃ³n** nos ayudan a estimar la relaciÃ³n entre dos variables, la **fuerza de la correlaciÃ³n** y la **direcciÃ³n de la relaciÃ³n** (positiva o negativa).  

- **Eje horizontal**: Variable independiente.  
- **Eje vertical**: Variable dependiente.  
- **Cada punto**: Un valor objetivo distinto.  
- **LÃ­nea ajustada**: Representa los valores predichos.  

### ğŸ“ˆ GrÃ¡fico de regresiÃ³n con Seaborn  
Para crear un grÃ¡fico de regresiÃ³n, utilizamos la funciÃ³n `regplot` de la librerÃ­a **Seaborn**.  

 Pasos:
1. Importamos Seaborn.  
2. Utilizamos la funciÃ³n `regplot()`, donde:  
   - `x` es la variable independiente.  
   - `y` es la variable dependiente.  
   - `data` es el nombre del DataFrame.  

El resultado es el grÃ¡fico de regresiÃ³n que muestra la relaciÃ³n entre las variables.  

### ğŸ“‰ GrÃ¡fico de residuales  
Un **grÃ¡fico de residuales** representa el error entre el valor real y el valor predicho. Se obtiene restando el valor predicho del valor real y se representa en el eje vertical, con la variable dependiente en el eje horizontal.  

 InterpretaciÃ³n:
- **DistribuciÃ³n aleatoria y varianza constante** â†’ Indica que un modelo lineal es apropiado.  
- **Curvatura en los residuales** â†’ Indica que el modelo lineal no es adecuado.  
- **Aumento de la varianza con `x`** â†’ Indica heterocedasticidad, lo que sugiere que el modelo no es el correcto.  

Para graficar los residuales en Seaborn, usamos `residplot()`.  

### ğŸ“Š GrÃ¡fico de distribuciÃ³n  
Un **grÃ¡fico de distribuciÃ³n** compara los valores predichos con los valores reales. Es Ãºtil cuando el modelo tiene mÃ¡s de una variable independiente.  

 Pasos:
1. Se cuentan y grafican los valores predichos y reales.  
2. Pandas convierte los valores continuos en una distribuciÃ³n (similar a un histograma).  
3. Se normaliza el eje vertical para que el Ã¡rea bajo la distribuciÃ³n sea igual a 1.  

 Ejemplo:
- **Valores reales** en rojo.  
- **Valores predichos** en azul.  
- Se observa quÃ© tan cerca estÃ¡n las predicciones de los valores reales.  

En **Seaborn**, para graficar la distribuciÃ³n usamos:  
```python
import seaborn as sns

sns.kdeplot(actual_values, color="red", label="Actual", fill=True)
sns.kdeplot(predicted_values, color="blue", label="Predicted", fill=True)
```

## **4. RegresiÃ³n PolinÃ³mica y TuberÃ­as (pipelines)**  
- Permite modelar relaciones no lineales entre las variables.  
- Se expresa como:  
  Y = Î²0 + Î²1 X + Î²2 X^2 + ... + Î²0_n X^n + Ïµ
 donde los tÃ©rminos elevados a potencias mayores a 1 capturan patrones mÃ¡s complejos en los datos.

### ğŸ”¢ Â¿CuÃ¡ndo usamos regresiÃ³n polinÃ³mica?
Cuando un modelo lineal **no se ajusta bien** a los datos, podemos utilizar una **regresiÃ³n polinÃ³mica**.  
Este mÃ©todo transforma los datos en un polinomio y luego aplica regresiÃ³n lineal para ajustar los parÃ¡metros.  
Es Ãºtil para describir **relaciones curvilÃ­neas**, que surgen al elevar las variables predictoras a exponentes mayores.  

### ğŸ“ˆ Tipos de modelos polinÃ³micos  
- **Modelo cuadrÃ¡tico (2Âº orden)**: La variable predictora se eleva al **cuadrado**.  
- **Modelo cÃºbico (3Âº orden)**: La variable predictora se eleva al **cubo**.  
- **Modelos de orden superior**: Se usan cuando un ajuste de 2Âº o 3Âº orden **no es suficiente**.  

ğŸ” **Ejemplo** de regresiÃ³n polinÃ³mica en Python utilizando `numpy.polyfit` para un modelo de **tercer orden**:  
```python
import numpy as np

x = np.array([...])  # Valores de la variable independiente
y = np.array([...])  # Valores de la variable dependiente

coeficientes = np.polyfit(x, y, 3)
print(coeficientes)
```

## Medidas para la evaluaciÃ³n en la muestra

DespuÃ©s de evaluar visualmente un modelo, es fundamental medir numÃ©ricamente su rendimiento. Para esto, utilizamos mÃ©tricas que determinan quÃ© tan bien se ajusta el modelo a nuestros datos. Dos medidas importantes son el **Error CuadrÃ¡tico Medio (MSE)** y el **Coeficiente de DeterminaciÃ³n (RÂ²)**.

### Error CuadrÃ¡tico Medio (MSE)
El **MSE (Mean Squared Error)** mide la diferencia entre los valores reales y los valores predichos, elevando al cuadrado estas diferencias y calculando su promedio.

#### CÃ¡lculo del MSE
Dado un conjunto de valores reales (y) y valores predichos (yÌ‚), el MSE se calcula como:

      MSE = (1/n) * Î£(yi-yÌ‚i)^2  

Ejemplo:
- Valor real: **150**
- Valor predicho: **50**
- Diferencia: 150 - 50 = 100
- Elevado al cuadrado: 100^2 = 10000

Para calcular el MSE en Python:

```python
from sklearn.metrics import mean_squared_error
mse = mean_squared_error(y_real, y_predicho)
```
### Coeficiente de determinaciÃ³n (RÂ²)
El RÂ² mide quÃ© tan cerca estÃ¡n los datos de la lÃ­nea de regresiÃ³n ajustada. Se interpreta como la proporciÃ³n de la variabilidad de la variable dependiente explicada por el modelo.

      CÃ¡lculo de RÂ²
      RÂ² = 1 âˆ’ ğ‘€ğ‘†ğ¸ğ‘šğ‘œğ‘‘ğ‘’ğ‘™ğ‘œ/ğ‘€ğ‘†ğ¸ğ‘šğ‘’ğ‘‘ğ‘–ğ‘

Donde:
      ğ‘€ğ‘†ğ¸ğ‘šğ‘œğ‘‘ğ‘’ğ‘™ğ‘œ es el MSE de la regresiÃ³n.
      ğ‘€ğ‘†ğ¸ğ‘šğ‘’ğ‘‘ğ‘–ğ‘ es el MSE de un modelo basado solo en la media de los valores reales.

InterpretaciÃ³n:

RÂ² cercano a 1 â†’ El modelo es un buen ajuste.

RÂ² cercano a 0 â†’ El modelo no explica la variabilidad de los datos.

RÂ² negativo â†’ Puede indicar sobreajuste.

Ejemplo en Python:
```python
from sklearn.linear_model import LinearRegression

modelo = LinearRegression()
modelo.fit(X_train, y_train)
r2 = modelo.score(X_test, y_test)
```
En este caso, si obtenemos un RÂ² de 0.49659, significa que el modelo explica aproximadamente 49.659% de la variabilidad de los datos.

### ConclusiÃ³n
El MSE nos indica el error absoluto del modelo, mientras que RÂ² mide la capacidad del modelo para explicar los datos. Un buen modelo debe minimizar el MSE y maximizar RÂ². En casos de RÂ² negativo, debemos revisar el modelo para evitar sobreajuste.

## **5. PredicciÃ³n y toma de decisiones**  
Esta seccion aborda la importancia de la predicciÃ³n y la toma de decisiones en modelos de regresiÃ³n. Se enfatiza la necesidad de validar los resultados del modelo mediante visualizaciÃ³n, medidas numÃ©ricas y comparaciÃ³n con otros modelos. Se presentan ejemplos de predicciÃ³n utilizando modelos de regresiÃ³n y se analiza la interpretaciÃ³n de los coeficientes. TambiÃ©n se explican los posibles problemas al extrapolar datos y cÃ³mo el anÃ¡lisis de los residuos puede indicar la necesidad de un modelo no lineal.

- Un modelo preciso permite estimar un valor justo para un auto usado considerando factores clave.  
- Si se excluyen caracterÃ­sticas relevantes, como el color en el ejemplo del auto rosa y rojo, el modelo puede hacer predicciones incorrectas.  
- Se pueden probar diferentes modelos y combinaciones de variables para mejorar la precisiÃ³n.
- 
### **IntroducciÃ³n**
La predicciÃ³n es un aspecto clave en la modelizaciÃ³n estadÃ­stica y el aprendizaje automÃ¡tico. Para validar un modelo, es fundamental asegurarse de que sus predicciones tienen sentido y no presentan valores extremos o ilÃ³gicos. AdemÃ¡s, se deben utilizar herramientas visuales y mÃ©tricas cuantitativas para evaluar su rendimiento.

### **EvaluaciÃ³n de predicciones**
- Un modelo debe ser validado a travÃ©s de visualizaciones y mÃ©tricas numÃ©ricas.
- Se usa el mÃ©todo `fit` para entrenar el modelo y el mÃ©todo `predict` para generar predicciones.
- Ejemplo: al predecir el precio de un automÃ³vil con un consumo de 30 millas por galÃ³n en carretera, el modelo estima un precio de **$13,771.30**, un valor razonable.

### **InterpretaciÃ³n de coeficientes**
- Los coeficientes (`coef_`) indican el impacto de las variables independientes sobre la variable dependiente.
- En una regresiÃ³n lineal simple, un aumento de **1 unidad en el consumo en carretera** reduce el precio en aproximadamente **$821**, lo cual parece coherente.

### **Problemas de extrapolaciÃ³n**
- Si se extiende el modelo a valores fuera del rango de entrenamiento, pueden surgir predicciones poco realistas.
- Ejemplo: al predecir el precio de un automÃ³vil con consumos entre **0 y 100 mpg**, se obtienen valores negativos, lo que indica que el modelo lineal no es adecuado para esos valores.

### **GeneraciÃ³n de secuencias de datos con NumPy**
- Para probar el modelo en diferentes rangos, se puede usar la funciÃ³n `np.arange()`, que genera secuencias de valores de un intervalo definido.
- Se recomienda analizar visualmente los resultados con grÃ¡ficos de regresiÃ³n.

### **EvaluaciÃ³n de modelos con mÃ©tricas estadÃ­sticas**
- **Error cuadrÃ¡tico medio (MSE)**: mide la desviaciÃ³n promedio al cuadrado de las predicciones respecto a los valores reales.
- **Coeficiente de determinaciÃ³n (RÂ²)**: mide quÃ© tan bien se ajusta el modelo a los datos (valores cercanos a 1 indican un buen ajuste).

### **ComparaciÃ³n de modelos y anÃ¡lisis de RÂ²**
- Ejemplo de valores de **RÂ²** y su interpretaciÃ³n:
  - **RÂ² = 0.9986**: el modelo se ajusta muy bien a los datos.
  - **RÂ² = 0.9226**: el modelo aÃºn tiene una fuerte relaciÃ³n lineal.
  - **RÂ² = 0.806**: los datos son mÃ¡s dispersos, pero la tendencia sigue siendo evidente.
  - **RÂ² = 0.61**: la relaciÃ³n lineal es mÃ¡s dÃ©bil.
- Un valor aceptable de **RÂ²** depende del Ã¡rea de estudio, pero se sugiere que sea al menos **0.10**.

### **ComparaciÃ³n entre modelos de regresiÃ³n**
- **RegresiÃ³n Lineal Simple (SLR) vs. RegresiÃ³n Lineal MÃºltiple (MLR)**:
  - **MLR** tiene un **MSE mÃ¡s bajo**, pero no siempre implica un mejor modelo.
  - La inclusiÃ³n de mÃ¡s variables en MLR reduce los errores, pero puede llevar al sobreajuste.
  - **RegresiÃ³n polinÃ³mica** suele reducir el **MSE**, pero puede generar problemas de interpretaciÃ³n.

### **Conclusiones**
- La predicciÃ³n y toma de decisiones requiere la validaciÃ³n rigurosa del modelo mediante mÃ©tricas y visualizaciones.
- Extrapolar datos fuera del rango de entrenamiento puede llevar a predicciones poco realistas.
- El anÃ¡lisis de residuos y grÃ¡ficos de regresiÃ³n ayudan a identificar patrones no lineales en los datos.
- **MSE y RÂ²** son herramientas clave para evaluar el rendimiento del modelo, pero deben interpretarse en contexto.
- Un menor MSE no siempre significa un mejor modelo, especialmente cuando se comparan modelos con distinta complejidad.

## **Conclusiones generales**  
El desarrollo de modelos predictivos es fundamental en el anÃ¡lisis de datos. Utilizar regresiÃ³n lineal simple, mÃºltiple o polinÃ³mica permite estimar el precio de un auto con distintos niveles de precisiÃ³n. La evaluaciÃ³n del modelo mediante (RÂ²) y MSE es clave para garantizar predicciones confiables. Adicional, incluir caracterÃ­sticas relevantes en el modelo mejora su exactitud, evitando errores en la toma de decisiones.

A estas alturas, ya lo sabe:

- **RegresiÃ³n lineal**: Se utiliza una variable independiente para hacer predicciones sobre una variable dependiente.
- **RegresiÃ³n lineal mÃºltiple**: Permite explicar la relaciÃ³n entre una variable objetivo continua y dos o mÃ¡s variables predictoras.
- **RegresiÃ³n lineal simple (SLR)**: MÃ©todo para comprender la relaciÃ³n entre dos variables: la variable independiente (`x`) y la dependiente (`y`).

### **EvaluaciÃ³n y visualizaciÃ³n del modelo**
- **GrÃ¡ficos de regresiÃ³n y residuales** con `regplot` y `residplot` de Seaborn ayudan a visualizar la relaciÃ³n entre las variables y evaluar la linealidad del modelo.
- **AnÃ¡lisis de residuos**: Lo ideal es que los residuos tengan media cero, estÃ©n distribuidos uniformemente y tengan una varianza constante. Si no se cumplen estas condiciones, es necesario ajustar el modelo.
- **GrÃ¡ficos de distribuciÃ³n**: Son Ãºtiles para comparar valores previstos y reales, especialmente en modelos con mÃºltiples variables independientes.

### **Modelado avanzado**
- **RegresiÃ³n polinÃ³mica**: El orden del polinomio influye en el ajuste del modelo. Se puede utilizar `polyfit` de NumPy para desarrollar modelos que se adapten mejor a los datos.
- **TransformaciÃ³n de caracterÃ­sticas**: Scikit-learn ofrece herramientas como `StandardScaler` para normalizar datos y `PolynomialFeatures` para transformar variables.
- **Canalizaciones (pipelines)**: Facilitan la automatizaciÃ³n de tareas como normalizaciÃ³n, transformaciÃ³n polinÃ³mica y predicciÃ³n, mejorando la eficiencia del proceso de modelado.

### **MÃ©tricas de evaluaciÃ³n del modelo**
- **Error cuadrÃ¡tico medio (MSE)**: Mide la media de los cuadrados de los errores entre los valores reales y los predichos.
- **Coeficiente de determinaciÃ³n (RÂ²)**: Indica quÃ© tan bien el modelo explica la varianza de la variable dependiente.
- Un **MSE bajo** y un **RÂ² alto** (cercano a 1) sugieren un buen ajuste, mientras que un **RÂ² negativo** puede indicar un sobreajuste o un modelo inadecuado.

### **Consideraciones finales**
- **ComparaciÃ³n de modelos**: Se deben evaluar diferentes modelos con medidas visuales y numÃ©ricas antes de elegir el mÃ¡s adecuado.
- **El MSE** es una de las mÃ©tricas mÃ¡s intuitivas para evaluar modelos de regresiÃ³n.
- **El grÃ¡fico de distribuciÃ³n** es una herramienta clave en regresiÃ³n lineal mÃºltiple.
- **El valor de RÂ² aceptable** depende del contexto y del caso de estudio.
- **AnÃ¡lisis de residuos**: Un buen modelo presenta residuos distribuidos aleatoriamente en torno a cero. Una tendencia en los residuos sugiere que el modelo puede necesitar ajustes o mÃ¡s datos.

Para evaluar y mejorar un modelo de regresiÃ³n, es fundamental utilizar herramientas de visualizaciÃ³n, mÃ©tricas numÃ©ricas y ajustes adecuados en la transformaciÃ³n de variables y selecciÃ³n del modelo.


## **Referencias**  
- Montgomery, D. C., Peck, E. A., & Vining, G. G. (2006). *[Introduction to Linear Regression Analysis.](https://drive.google.com/file/d/1Wv_kAbiQJoOJxIy6uOTEzImuBp76cNIP/view?usp=sharing)* John Wiley & Sons.  
- Hastie, T., Tibshirani, R., & Friedman, J. (2009). *[The Elements of Statistical Learning: Data Mining, Inference, and Prediction.](https://drive.google.com/file/d/12Y0plBCAhXK13007O_GkTY-3IjzoN5GO/view?usp=sharing)* Springer.  
- [DocumentaciÃ³n de `sklearn.metrics` para el cÃ¡lculo de `mean_squared_error` y `r2_score`.](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html)
- [DocumentaciÃ³n de NumPy sobre `np.arange()` para la generaciÃ³n de secuencias numÃ©ricas.](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html)

---

## Notebooks de practica

- [Desarrollo de modelo 1]()
- [Desarrollo de modelo 2]()
